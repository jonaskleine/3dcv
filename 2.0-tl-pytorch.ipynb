{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please Note**: We updated the requirements.txt\n",
    "\n",
    "Please install the new requirements before editing this exercise."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from vll.utils.download import download_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage\n",
    "import skimage.io\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "from models.mnist.simple_cnn import Net"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "(2 points)\n",
    "\n",
    "In this task, you will learn some basic tensor operations using the PyTorch library.\n",
    "\n",
    "Reference for torch: https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "        14., 15., 16., 17., 18., 19.])\n",
      "tensor([ 0.0000,  0.3274,  0.8937,  2.1220,  2.8266,  1.8614,  5.7118,  1.7785,\n",
      "         1.2112,  1.1061,  5.9489,  6.0703, 11.8717,  1.6388,  1.3497,  7.3098,\n",
      "         0.1905, 14.3708,  6.6088,  5.7197])\n",
      "tensor([-1.0000, -0.6726, -0.1063,  1.1220,  1.8266,  0.8614,  4.7118,  0.7785,\n",
      "         0.2112,  0.1061,  4.9489,  5.0703, 10.8717,  0.6388,  0.3497,  6.3098,\n",
      "        -0.8095, 13.3708,  5.6088,  4.7197])\n",
      "tensor(1.8266)\n",
      "tensor([-0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# Create a numpy array that looks like this: [0, 1, 2, ..., 19]\n",
    "arr = arr = np.arange(20)\n",
    "\n",
    "# Convert the numpy array to a torch tensor\n",
    "tensor = torch.tensor(arr,dtype=torch.float32)\n",
    "print(tensor)\n",
    "\n",
    "# Create a tensor that contains random numbers.\n",
    "# It should have the same size like the numpy array.\n",
    "# Multiply it with the previous tensor.\n",
    "rand_tensor = torch.rand_like(tensor)\n",
    "tensor *= rand_tensor\n",
    "print(tensor)\n",
    "\n",
    "# Create a tensor that contains only 1s.\n",
    "# It should have the same size like the numpy array.\n",
    "# Substract it from the previous tensor.\n",
    "tensor -= torch.ones_like(tensor)\n",
    "print(tensor)\n",
    "\n",
    "# Get the 5th element using a index.\n",
    "element = tensor[4]\n",
    "print(element)\n",
    "\n",
    "# Create a tensor that contains only 0s.\n",
    "# It should have the same size like the numpy array.\n",
    "# Multiply it with the previous tensor without any assignment (in place).\n",
    "tensor *= 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512])\n",
      "786432\n",
      "torch.Size([1, 786432])\n",
      "torch.Size([786432])\n",
      "torch.Size([3, 512, 512])\n",
      "tensor(358450.)\n",
      "tensor(0.4558)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "from skimage import io, color\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import vll\n",
    "# Load the image from the last exercise as RGB image.\n",
    "image_path = \"vll/data/data/pepo.jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "# Convert the image to a tensor\n",
    "transform = transforms.ToTensor()\n",
    "image_tensor = transform(image)\n",
    "\n",
    "# Print its shape\n",
    "print(image_tensor.shape)\n",
    "\n",
    "# Flatten the image\n",
    "flattened_image = image_tensor.view(-1)\n",
    "print(len(flattened_image))\n",
    "\n",
    "# Add another dimension resulting in a 1x78643 tensor\n",
    "expanded_image = flattened_image.unsqueeze(0)\n",
    "print(expanded_image.shape)\n",
    "\n",
    "# Revert the last action\n",
    "reverted_image = expanded_image.squeeze(0)\n",
    "print(reverted_image.shape)\n",
    "\n",
    "# Reshape the tensor, so that it has the original 2D dimensions\n",
    "reshaped_image = reverted_image.view(image_tensor.shape)\n",
    "print(reshaped_image.shape)\n",
    "\n",
    "# Calculate the sum, mean and max of the tensor\n",
    "print(torch.sum(reshaped_image))\n",
    "print(torch.mean(reshaped_image))\n",
    "print(torch.max(reshaped_image))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "(2 points)\n",
    "\n",
    "Use Autograd to perform operations on a tensor and output then gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[0.4591, 0.6001],\n",
      "        [0.2659, 0.6594]], requires_grad=True)\n",
      "y: tensor([[2.4591, 2.6001],\n",
      "        [2.2659, 2.6594]], grad_fn=<AddBackward0>)\n",
      "z: tensor([[6.0472, 6.7604],\n",
      "        [5.1342, 7.0725]], grad_fn=<PowBackward0>)\n",
      "out: tensor(6.2536, grad_fn=<MeanBackward0>)\n",
      "Gradients of out with respect to x:\n",
      "tensor([[1.2295, 1.3000],\n",
      "        [1.1329, 1.3297]])\n",
      "Does y2 require gradients? False\n",
      "out2 (with gradients globally disabled): tensor(6.2536)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Create a random 2x2 tensor which requires gradients\n",
    "x = torch.rand((2, 2), requires_grad=True)\n",
    "print(\"x:\",x)\n",
    "\n",
    "# Create another tensor by adding 2.0\n",
    "y = x + 2.0\n",
    "print(\"y:\", y)\n",
    "\n",
    "# Create a third tensor z = y^2\n",
    "z = y ** 2\n",
    "print(\"z:\", z)\n",
    "\n",
    "# Compute out as the mean of values in z\n",
    "out = z.mean()\n",
    "print(\"out:\", out)\n",
    "\n",
    "# Perform back propagation on out\n",
    "out.backward()\n",
    "# Print the gradients dout/dx\n",
    "print(\"Gradients of out with respect to x:\")\n",
    "print(x.grad)\n",
    "\n",
    "# Create a copy of y whithout gradients\n",
    "y2 = y.detach().clone()\n",
    "print(\"Does y2 require gradients?\", y2.requires_grad)\n",
    "\n",
    "# Perform the mean operation on z\n",
    "# with gradients globally disabled\n",
    "with torch.no_grad():\n",
    "    out2 = z.mean()\n",
    "\n",
    "print(\"out2 (with gradients globally disabled):\", out2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "(3 points)\n",
    "\n",
    "Implement a Dataset class for MNIST.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./models/mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 11390718.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./models/mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./models/mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./models/mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 277810.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./models/mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./models/mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./models/mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./models/mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1152614.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./models/mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./models/mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./models/mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4534760.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./models/mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./models/mnist\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We first download the MNIST dataset\n",
    "import os\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define the function to download MNIST dataset\n",
    "def download_mnist(root=\"./models/mnist\"):\n",
    "    if not os.path.exists(root):\n",
    "        os.makedirs(root)\n",
    "    MNIST(root=root, train=True, download=True)\n",
    "    MNIST(root=root, train=False, download=True)\n",
    "\n",
    "# Define custom Dataset class for MNIST\n",
    "class CustomMNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, train=True, transform=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        # Download MNIST dataset if not available\n",
    "        if not os.path.exists(root):\n",
    "            download_mnist(root)\n",
    "\n",
    "        # Initialize MNIST dataset\n",
    "        self.mnist_data = MNIST(root=root, train=train, transform=transform, download=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mnist_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.mnist_data[idx]\n",
    "        return image, label\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Download MNIST dataset if not already available\n",
    "    download_mnist()\n",
    "\n",
    "    # Define transformation for the dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Convert PIL image to tensor\n",
    "        transforms.Normalize((0.1307,), (0.3081,))  # Normalize the image\n",
    "    ])\n",
    "\n",
    "    # Instantiate the custom MNIST dataset class\n",
    "    mnist_dataset = CustomMNISTDataset(root=\"./data\", train=True, transform=transform)\n",
    "\n",
    "    # Example usage:\n",
    "    # mnist_loader = torch.utils.data.DataLoader(mnist_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "download_mnist()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST:\n",
    "    \"\"\"\n",
    "    Dataset class for MNIST\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, transform=None):\n",
    "        \"\"\"\n",
    "        root -- path to either \"training\" or \"testing\"\n",
    "        \n",
    "        transform -- transform (from torchvision.transforms)\n",
    "                     to be applied to the data\n",
    "        \"\"\"\n",
    "        # save transforms\n",
    "        self.transform = transform\n",
    "        \n",
    "        # TODO: create a list of all subdirectories (named like the classes) \n",
    "        #       within the dataset root\n",
    "        self.classes = sorted(os.listdir(root))\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # TODO: create a list of paths to all images\n",
    "        #       with the ground truth label\n",
    "        self.images = []\n",
    "        for cls in self.classes:\n",
    "            cls_dir = os.path.join(root, cls)\n",
    "            for image_name in os.listdir(cls_dir):\n",
    "                image_path = os.path.join(cls_dir, image_name)\n",
    "                self.images.append((image_path, self.class_to_idx[cls]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the lenght of the dataset (number of images)\n",
    "        \"\"\"\n",
    "        # TODO: return the length (number of images) of the dataset\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Loads and returns one image as floating point numpy array\n",
    "        \n",
    "        index -- image index in [0, self.__len__() - 1]\n",
    "        \"\"\"\n",
    "        # TODO: load the ith image as an numpy array (dtype=float32)\n",
    "        image_path, label = self.images[index]\n",
    "        image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "        image = np.array(image, dtype=np.float32)\n",
    "        \n",
    "        # TODO: apply transforms to the image (if there are any)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # TODO: return a tuple (transformed image, ground truth)\n",
    "        return image, label\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "(3 points)\n",
    "\n",
    "You can now load a pretrained neural network model we provide.\n",
    "Your last task is to run the model on the MNIST test dataset, plot some example images with the predicted labels and compute the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: './models/mnist\\\\simple_cnn.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 58\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# create a DataLoader using the implemented MNIST dataset class\u001b[39;00m\n\u001b[0;32m     57\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m---> 58\u001b[0m     \u001b[43mMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./models/mnist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1307\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.3081\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     63\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# create the neural network\u001b[39;00m\n\u001b[0;32m     66\u001b[0m model \u001b[38;5;241m=\u001b[39m Net()\n",
      "Cell \u001b[1;32mIn[18], line 26\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[1;34m(self, root, transform)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses:\n\u001b[0;32m     25\u001b[0m     cls_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     27\u001b[0m         image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cls_dir, image_name)\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages\u001b[38;5;241m.\u001b[39mappend((image_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_to_idx[\u001b[38;5;28mcls\u001b[39m]))\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: './models/mnist\\\\simple_cnn.py'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from models.mnist.simple_cnn import Net\n",
    "\n",
    "\n",
    "def validate(model, data_loader):\n",
    "    # TODO: Create a 10x10 grid of subplots\n",
    "   \n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0 # count for correct predictions\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, item in enumerate(data_loader):\n",
    "            # TODO: unpack item into image and ground truth\n",
    "            #       and run network on them\n",
    "            image, label = item\n",
    "            output = model(image)\n",
    "\n",
    "            # TODO: get class with highest probability\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            \n",
    "            # TODO: check if prediction is correct\n",
    "            #       and add it to correct count\n",
    "            correct += (predicted == label).sum().item()\n",
    "            \n",
    "            # plot the first 100 images\n",
    "            if i < 100:\n",
    "                # TODO: compute position of ith image in the grid\n",
    "                plt.subplot(10, 10, i + 1)\n",
    "                row = i // 10\n",
    "                col = i % 10\n",
    "                # TODO: convert image tensor to numpy array\n",
    "                #       and normalize to [0, 1]\n",
    "                image_np = image.squeeze().numpy()\n",
    "                image_np = (image_np - image_np.min()) / (image_np.max() - image_np.min())\n",
    "                \n",
    "                # TODO: make wrongly predicted images red\n",
    "                if predicted != label:\n",
    "                    plt.imshow(image_np, cmap='gray', vmin=0, vmax=1)\n",
    "                else:\n",
    "                    plt.imshow(image_np, cmap='gray')\n",
    "                \n",
    "                # TODO: disable axis and show image\n",
    "                plt.axis('off')\n",
    "                \n",
    "                # TODO: show the predicted class next to each image\n",
    "                plt.title(f'Predicted: {predicted.item()}, Actual: {label.item()}')\n",
    "            \n",
    "            elif i == 100:\n",
    "                plt.show()\n",
    "    \n",
    "    # TODO: compute and print the prediction accuracy in percent\n",
    "    accuracy = correct / len(data_loader.dataset)\n",
    "    print(f\"Prediction accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# create a DataLoader using the implemented MNIST dataset class\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    MNIST('./models/mnist',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=1, shuffle=True)\n",
    "\n",
    "# create the neural network\n",
    "model = Net()\n",
    "\n",
    "# load the statedict from 'models/mnist/simple_cnn.pt'\n",
    "model.load_state_dict(torch.load('./models/mnist/simplecnn.pt'))\n",
    "\n",
    "# validate the model\n",
    "validate(model, data_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
